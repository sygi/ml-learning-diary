{
 "metadata": {
  "name": "",
  "signature": "sha256:60f6bb6ace173faee1b8e9667b4e887175796649b0d8629f54d6e1660d07ecc9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "import gym"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_output(params, obs):\n",
      "\n",
      "  weights = tf.slice(params, [0], [4])\n",
      "  obs_reshaped = tf.reshape(obs, [-1, 4])\n",
      "  bias = params[-1]\n",
      "  #obs2 = tf.Print(obs_reshaped, [tf.shape(obs_reshaped), tf.shape(weights), tf.shape(tf.mul(obs_reshaped, weights))], message=\"obs shape\")\n",
      "  activation = tf.reduce_sum(tf.mul(obs_reshaped, weights), 1) + bias\n",
      "  #activation2 = tf.Print(activation, [activation, tf.shape(activation)], message=\"activation\")\n",
      "  return tf.sigmoid(activation)  # probability of choosing move 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_get_output(sess):\n",
      "  from math import exp\n",
      "  def sigmoid(x): return 1./(1. + exp(-x))\n",
      "  \n",
      "  params = [1., 2., 3., 4., 5.]\n",
      "  obs = [0.4, 6., 8., 5.]\n",
      "  activation = 0.4 + 12 + 24 + 20 + 5\n",
      "  output = sess.run(get_output(params, obs))\n",
      "  print(output, [sigmoid(activation)])\n",
      "  assert abs(output - [sigmoid(activation)]) < 1e-6\n",
      "  \n",
      "  obs = [[0.4, 6., -3., 5.], [0.8, -0.5, 0.6, -0.01]]\n",
      "  activation = [0.4 + 12 - 9 + 20 + 5, 0.8 - 1. + 1.8 - 0.04 +5]\n",
      "  after_activ = map(sigmoid, activation)\n",
      "  output = sess.run(get_output(params, obs))\n",
      "  assert abs(sum(output - after_activ)) < 1e-7"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_action(output):\n",
      "  probs = tf.transpose(tf.pack([output, 1. - output]))\n",
      "  return tf.reshape(tf.multinomial(tf.log(probs), 1), [-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_get_action(sess):\n",
      "  output = [0.99, 0.001, 0.001]\n",
      "  actions = sess.run(get_action(tf.convert_to_tensor(output)))\n",
      "  print(actions)\n",
      "  assert (actions == [0, 1, 1]).all()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_loss(output, actions, reward, average_reward, num_moves):\n",
      "  eps =  1e-16\n",
      "  #output2 = tf.Print(output, [output, tf.shape(output), tf.shape(actions)], message=\"output\")\n",
      "  pred = tf.equal(actions, 0)\n",
      "  move_ids = tf.cast(tf.range(num_moves), tf.float32)\n",
      "  \n",
      "  select = tf.select(pred, tf.log(output + eps), tf.log(1. + eps - output))\n",
      "  #select2 = tf.Print(select, [select, average_reward], message=\"select\")\n",
      "  advantage = (reward - average_reward) - move_ids\n",
      "  #advantage2 = tf.Print(advantage, [advantage], message=\"advantage\")\n",
      "  return tf.reduce_sum(tf.mul(advantage, select))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def test_get_loss(sess):\n",
      "  from math import log\n",
      "  outputs = [0.55, 0.7, 0.1]  # probabilities of choosing 0\n",
      "  actions = [0, 1, 0]\n",
      "  log_probs = [log(0.55), log(0.3), log(0.1)]\n",
      "  reward = 4.\n",
      "  num_moves = len(outputs)\n",
      "  \n",
      "  my_loss = sess.run(get_loss(outputs, actions, reward, num_moves))\n",
      "  print(my_loss, reward * np.sum(log_probs))\n",
      "  assert abs(my_loss - reward * np.sum(log_probs)) < 1e-6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_model(params, output, obs_place, action, render=False):\n",
      "  env.reset()\n",
      "  assert env.action_space.n == 2\n",
      "  first_action = env.action_space.sample()\n",
      "  obs, rew, done, _ = env.step(first_action)\n",
      "  reward = rew\n",
      "  observations = []\n",
      "  actions = []\n",
      "  while not done:\n",
      "    if reward >= 1000:\n",
      "      break\n",
      "    if render:\n",
      "      env.render()\n",
      "    action_eval = sess.run(action, feed_dict={obs_place: obs})[0]\n",
      "    observations.append(obs)\n",
      "    actions.append(action_eval)\n",
      "    \n",
      "    obs, rew, done, _ = env.step(action_eval)\n",
      "    reward += rew\n",
      "  env.close()\n",
      "  return (reward, np.vstack(observations), actions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_session():\n",
      "  config = tf.ConfigProto(operation_timeout_in_ms=5000)\n",
      "  return tf.Session(config=config)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import shutil\n",
      "env = gym.make(\"CartPole-v1\")\n",
      "rounds=5000\n",
      "\n",
      "tf.reset_default_graph()\n",
      "\n",
      "with get_session() as sess:\n",
      "  theta = tf.Variable([0.] * 5, dtype=tf.float32, name=\"theta\")\n",
      "  observation_place = tf.placeholder(tf.float32, shape=None)\n",
      "  action_place = tf.placeholder(tf.float32, shape=None)\n",
      "  reward_place = tf.placeholder(tf.float32, shape=None)\n",
      "  num_moves_place = tf.placeholder(tf.int32, shape=None)\n",
      "  average_place = tf.placeholder(tf.float32, shape=None)\n",
      "  \n",
      "  output = get_output(theta, observation_place)\n",
      "  action = get_action(output)\n",
      "  \n",
      "  loss = get_loss(output, action_place, reward_place, average_place, num_moves_place)\n",
      "  loss_grad = tf.gradients(loss, [theta])[0]\n",
      "  learning_rate = 0.0001\n",
      "  gradient_place = tf.placeholder(tf.float32, shape=None)\n",
      "  \n",
      "  params_update_op = tf.assign_add(theta, gradient_place)\n",
      "  \n",
      "  sess.run(tf.initialize_all_variables())\n",
      "  \n",
      "  sum_rewards = 0.\n",
      "  #test_get_action(sess)\n",
      "  #test_get_output(sess)\n",
      "  for i in range(rounds):\n",
      "    #print(\"theta:\", sess.run(theta))\n",
      "    rew, observations, actions = run_model(theta, output, observation_place, action)\n",
      "    sum_rewards += rew\n",
      "    loss_ev, loss_grad_ev = sess.run([loss, loss_grad],\n",
      "                                     feed_dict={observation_place: observations, action_place: actions,\n",
      "                                                reward_place: rew, average_place: min(100., (sum_rewards / (i+1))),\n",
      "                                                num_moves_place: observations.shape[0]})\n",
      "    #print(\"reward:\", rew, \"\\nobservations: \", observations, \"\\nobs sum:\", np.sum(observations, axis=0),\n",
      "    #      \"\\nactions:\", actions, \"\\ngradients:\", loss_grad_ev)\n",
      "    sess.run(params_update_op, feed_dict={gradient_place: loss_grad_ev * learning_rate})\n",
      "    print(i, rew)\n",
      "    prev = rew\n",
      "  shutil.rmtree(\"/tmp/pg1\")\n",
      "  writer = tf.train.SummaryWriter(\"/tmp/pg1\", sess.graph)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}