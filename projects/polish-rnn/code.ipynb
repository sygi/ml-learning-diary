{
 "metadata": {
  "name": "",
  "signature": "sha256:4ecc55c86eb6514fabf7a0f316efc1db59a3a62ef49875205ac45ce0fe61a04e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "nltk.data.path.append(\"/home/sygi/ml-stats/data/nltk_data/\")\n",
      "import numpy as np\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "from builtins import open\n",
      "f = open(\"pan-tadeusz.txt\", 'r', encoding='utf-8').read().lower()\n",
      "g = re.sub('\\n\\n', '\\n', f)\n",
      "lines = g.split(\"\\n\")\n",
      "paragraphs = [a + \"\\n\" + b for a,b in zip(lines, lines[1:])][::2]\n",
      "seq_len = max(map(len, paragraphs)) + 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chars = list(set(\"\".join(paragraphs)).union(set(\"@^\")))\n",
      "chars_n = len(chars)\n",
      "chars_ids = dict(zip(chars, range(chars_n)))\n",
      "one_hot_f = lambda x: [1 if x == i else 0 for i in range(chars_n)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_sentence(sentence, seq_len=seq_len):\n",
      "  sentence = \"^\" + sentence + \"@\"\n",
      "  if len(sentence) <= seq_len:\n",
      "    while len(sentence) <= seq_len:\n",
      "      sentence = sentence + \"@\"\n",
      "    return [(sentence[:-1], sentence[1:])]\n",
      "  batches_n = len(sentence) - seq_len + 1\n",
      "  return [(sentence[start:start + seq_len], sentence[start+1 : start + seq_len + 1]) for start in range(0, batches_n, 30)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "data_split = map(lambda sen: split_sentence(sen), paragraphs)\n",
      "data_split_flat = [ex for sen in data_split for ex in sen]\n",
      "random.shuffle(data_split_flat)\n",
      "\n",
      "inputs = map(lambda x: x[0], data_split_flat)\n",
      "outputs = map(lambda x: x[1], data_split_flat)\n",
      "\n",
      "make_one_hot = lambda x: [[one_hot_f(chars_ids[char]) for char in seq] for seq in x]\n",
      "inputs_one_hot = make_one_hot(inputs)\n",
      "output_labels = [[chars_ids[char] for char in seq] for seq in outputs]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers import Merge, LSTM, Dense, wrappers\n",
      "from keras.layers.core import Masking\n",
      "from keras.layers.recurrent import SimpleRNN\n",
      "from keras.optimizers import Adam\n",
      "from keras import backend as K"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using TensorFlow backend.\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def my_crossentropy(y_true, y_pred):\n",
      "    '''Just another crossentropy'''\n",
      "    \n",
      "    y_true = K.squeeze(y_true, 2)\n",
      "    y_true = K.one_hot(K.cast(y_true, 'int32'), chars_n)\n",
      "    \n",
      "    y_pred = K.clip(y_pred, K.epsilon(), 1.0 - K.epsilon())\n",
      "    y_pred = K.log(y_pred)\n",
      "    loss = -K.sum(y_true * y_pred)\n",
      "    return loss\n",
      "# TODO: unit test for that\n",
      "\n",
      "# input size: (batch_size, seq_length, chars_n)\n",
      "model = Sequential()\n",
      "model.add(LSTM(1000, input_length=seq_len, input_dim=chars_n, return_sequences=True))\n",
      "# shape: (batch_size, seq_length, 1000)\n",
      "model.add(wrappers.TimeDistributed(Dense(chars_n, activation='softmax')))\n",
      "# shape: (batch_size, seq_length, chars_n)\n",
      "model.compile(loss=my_crossentropy,\n",
      "              optimizer=AdamWithWeightnorm(),\n",
      "              metrics=['sparse_categorical_accuracy'])\n",
      "model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "____________________________________________________________________________________________________\n",
        "Layer (type)                     Output Shape          Param #     Connected to                     \n",
        "====================================================================================================\n",
        "lstm_2 (LSTM)                    (None, 112, 1000)     4228000     lstm_input_2[0][0]               \n",
        "____________________________________________________________________________________________________\n",
        "timedistributed_2 (TimeDistribut (None, 112, 56)       56056       lstm_2[0][0]                     \n",
        "====================================================================================================\n",
        "Total params: 4,284,056\n",
        "Trainable params: 4,284,056\n",
        "Non-trainable params: 0\n",
        "____________________________________________________________________________________________________\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_based_init(model, inputs_one_hot[:100])\n",
      "model.fit(inputs_one_hot, np.expand_dims(output_labels, -1),\n",
      "          batch_size=32, nb_epoch=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Performing data dependent initialization for layer lstm_2\n",
        "(1000,)\n",
        "(56, 4000)\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "Dimensions must be equal, but are 4000 and 1000",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-22-a2cd39d81dfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_based_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_one_hot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m model.fit(inputs_one_hot, np.expand_dims(output_labels, -1),\n\u001b[1;32m      3\u001b[0m           batch_size=32, nb_epoch=20)\n",
        "\u001b[0;32m<ipython-input-21-8941e66db4b2>\u001b[0m in \u001b[0;36mdata_based_init\u001b[0;34m(model, input)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mnew_W\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mW\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_W\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.pyc\u001b[0m in \u001b[0;36mdiv\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m   \"\"\"\n\u001b[0;32m--> 705\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op_def_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Div\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    747\u001b[0m           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    748\u001b[0m                            \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m                            op_def=op_def)\n\u001b[0m\u001b[1;32m    750\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m           return _Restructure(ops.convert_n_to_tensor(outputs),\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2380\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2382\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2383\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1781\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[1;32m   1782\u001b[0m                          % op.type)\n\u001b[0;32m-> 1783\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m     raise RuntimeError(\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, debug_python_shape_fn)\u001b[0m\n\u001b[1;32m    594\u001b[0m                                                              status)\n\u001b[1;32m    595\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m   \u001b[0;31m# Convert TensorShapeProto values in output_shapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 4000 and 1000"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mnrnd(probs):\n",
      "    rnd = np.random.random()\n",
      "    for i in xrange(len(probs)):\n",
      "        rnd -= probs[i]\n",
      "        if rnd <= 0:\n",
      "            return i\n",
      "    return len(probs) - 1\n",
      "  \n",
      "def generate(batch_size=2, seq_len=seq_len-1, dim=chars_n):\n",
      "  sentences = np.zeros((batch_size, seq_len+1, dim))\n",
      "  sentences[:, 0, chars_ids['^']] = 1\n",
      "  for i in np.arange(seq_len):\n",
      "    probs = model.predict_proba(sentences)[:,i,:]\n",
      "    # Go over each sequence and sample the i-th character.\n",
      "    for j in np.arange(len(sentences)):\n",
      "        sentences[j, i+1, mnrnd(probs[j, :])] = 1\n",
      "  sentences = [sentence[1:].nonzero()[1] for sentence in sentences]\n",
      "\n",
      "  # Convert to readable text.\n",
      "  text = []\n",
      "  for sentence in sentences:\n",
      "    text.append(unicode(''.join([chars[char] for char in sentence])))\n",
      "  return text\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outs = generate()\n",
      "print(outs[0])\n",
      "print(outs[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r",
        "2/2 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\u015b\u0142odki\u00e9j \u017cy\u0142y s postrzemnu,\n",
        "juk pokrze pasta\u0142zi nadyk,\n",
        "i o a\u0142 wija, gryemum! brzerta niego\u0144tumita\u0142@@@@@@@@@@@@@\n",
        "trgo bi\u0119d\u0105w przebadzie opodli nagr\u0119 nasie\n",
        "z ranis\u0142oy sorzewo\u0142y oliby \u0142obies\u0142em,@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = \"b\\xc4\\x99rz\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"\".join(chars))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Z\u0104\u0106\n",
        "\u0118\u015b \"(\u00ab,.248\u00bb:@\u0142DF\u00c9HJLNP\u00d3RTVX\u015a^bdf\u00e9hjlnp\u00f3rtvx\u017a\u017cA\u0105\u0107B\u0119\u0144!%')-1359;?\u0141CEGIKMOSUWY[]_a\u00e0czegikmosuwy\u017b}\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras import backend as K\n",
      "from keras.optimizers import SGD,Adam\n",
      "import tensorflow as tf\n",
      "\n",
      "# adapted from keras.optimizers.SGD\n",
      "class SGDWithWeightnorm(SGD):\n",
      "    def get_updates(self, params, constraints, loss):\n",
      "        grads = self.get_gradients(loss, params)\n",
      "        self.updates = []\n",
      "\n",
      "        lr = self.lr\n",
      "        if self.inital_decay > 0:\n",
      "            lr *= (1. / (1. + self.decay * self.iterations))\n",
      "            self.updates .append(K.update_add(self.iterations, 1))\n",
      "\n",
      "        # momentum\n",
      "        shapes = [K.get_variable_shape(p) for p in params]\n",
      "        moments = [K.zeros(shape) for shape in shapes]\n",
      "        self.weights = [self.iterations] + moments\n",
      "        for p, g, m in zip(params, grads, moments):\n",
      "\n",
      "            # if a weight tensor (len > 1) use weight normalized parameterization\n",
      "            ps = K.get_variable_shape(p)\n",
      "            if len(ps) > 1:\n",
      "\n",
      "                # get weight normalization parameters\n",
      "                V, V_norm, V_scaler, g_param, grad_g, grad_V = get_weightnorm_params_and_grads(p, g)\n",
      "\n",
      "                # momentum container for the 'g' parameter\n",
      "                V_scaler_shape = K.get_variable_shape(V_scaler)\n",
      "                m_g = K.zeros(V_scaler_shape)\n",
      "\n",
      "                # update g parameters\n",
      "                v_g = self.momentum * m_g - lr * grad_g  # velocity\n",
      "                self.updates.append(K.update(m_g, v_g))\n",
      "                if self.nesterov:\n",
      "                    new_g_param = g_param + self.momentum * v_g - lr * grad_g\n",
      "                else:\n",
      "                    new_g_param = g_param + v_g\n",
      "\n",
      "                # update V parameters\n",
      "                v_v = self.momentum * m - lr * grad_V  # velocity\n",
      "                self.updates.append(K.update(m, v_v))\n",
      "                if self.nesterov:\n",
      "                    new_V_param = V + self.momentum * v_v - lr * grad_V\n",
      "                else:\n",
      "                    new_V_param = V + v_v\n",
      "\n",
      "                # if there are constraints we apply them to V, not W\n",
      "                if p in constraints:\n",
      "                    c = constraints[p]\n",
      "                    new_V_param = c(new_V_param)\n",
      "\n",
      "                # wn param updates --> W updates\n",
      "                add_weightnorm_param_updates(self.updates, new_V_param, new_g_param, p, V_scaler)\n",
      "\n",
      "            else: # normal SGD with momentum\n",
      "                v = self.momentum * m - lr * g  # velocity\n",
      "                self.updates.append(K.update(m, v))\n",
      "\n",
      "                if self.nesterov:\n",
      "                    new_p = p + self.momentum * v - lr * g\n",
      "                else:\n",
      "                    new_p = p + v\n",
      "\n",
      "                # apply constraints\n",
      "                if p in constraints:\n",
      "                    c = constraints[p]\n",
      "                    new_p = c(new_p)\n",
      "\n",
      "                self.updates.append(K.update(p, new_p))\n",
      "        return self.updates\n",
      "\n",
      "# adapted from keras.optimizers.Adam\n",
      "class AdamWithWeightnorm(Adam):\n",
      "    def get_updates(self, params, constraints, loss):\n",
      "        grads = self.get_gradients(loss, params)\n",
      "        self.updates = [K.update_add(self.iterations, 1)]\n",
      "\n",
      "        lr = self.lr\n",
      "        if self.inital_decay > 0:\n",
      "            lr *= (1. / (1. + self.decay * self.iterations))\n",
      "\n",
      "        t = self.iterations + 1\n",
      "        lr_t = lr * K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t))\n",
      "\n",
      "        shapes = [K.get_variable_shape(p) for p in params]\n",
      "        ms = [K.zeros(shape) for shape in shapes]\n",
      "        vs = [K.zeros(shape) for shape in shapes]\n",
      "        self.weights = [self.iterations] + ms + vs\n",
      "\n",
      "        for p, g, m, v in zip(params, grads, ms, vs):\n",
      "\n",
      "            # if a weight tensor (len > 1) use weight normalized parameterization\n",
      "            # this is the only part changed w.r.t. keras.optimizers.Adam\n",
      "            ps = K.get_variable_shape(p)\n",
      "            if len(ps)>1:\n",
      "\n",
      "                # get weight normalization parameters\n",
      "                V, V_norm, V_scaler, g_param, grad_g, grad_V = get_weightnorm_params_and_grads(p, g)\n",
      "\n",
      "                # Adam containers for the 'g' parameter\n",
      "                V_scaler_shape = K.get_variable_shape(V_scaler)\n",
      "                m_g = K.zeros(V_scaler_shape)\n",
      "                v_g = K.zeros(V_scaler_shape)\n",
      "\n",
      "                # update g parameters\n",
      "                m_g_t = (self.beta_1 * m_g) + (1. - self.beta_1) * grad_g\n",
      "                v_g_t = (self.beta_2 * v_g) + (1. - self.beta_2) * K.square(grad_g)\n",
      "                new_g_param = g_param - lr_t * m_g_t / (K.sqrt(v_g_t) + self.epsilon)\n",
      "                self.updates.append(K.update(m_g, m_g_t))\n",
      "                self.updates.append(K.update(v_g, v_g_t))\n",
      "\n",
      "                # update V parameters\n",
      "                m_t = (self.beta_1 * m) + (1. - self.beta_1) * grad_V\n",
      "                v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(grad_V)\n",
      "                new_V_param = V - lr_t * m_t / (K.sqrt(v_t) + self.epsilon)\n",
      "                self.updates.append(K.update(m, m_t))\n",
      "                self.updates.append(K.update(v, v_t))\n",
      "\n",
      "                # if there are constraints we apply them to V, not W\n",
      "                if p in constraints:\n",
      "                    c = constraints[p]\n",
      "                    new_V_param = c(new_V_param)\n",
      "\n",
      "                # wn param updates --> W updates\n",
      "                add_weightnorm_param_updates(self.updates, new_V_param, new_g_param, p, V_scaler)\n",
      "\n",
      "            else: # do optimization normally\n",
      "                m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
      "                v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
      "                p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon)\n",
      "\n",
      "                self.updates.append(K.update(m, m_t))\n",
      "                self.updates.append(K.update(v, v_t))\n",
      "\n",
      "                new_p = p_t\n",
      "                # apply constraints\n",
      "                if p in constraints:\n",
      "                    c = constraints[p]\n",
      "                    new_p = c(new_p)\n",
      "                self.updates.append(K.update(p, new_p))\n",
      "        return self.updates\n",
      "\n",
      "\n",
      "def get_weightnorm_params_and_grads(p, g):\n",
      "    ps = K.get_variable_shape(p)\n",
      "\n",
      "    # construct weight scaler: V_scaler = g/||V||\n",
      "    V_scaler_shape = (ps[-1],)  # assumes we're using tensorflow!\n",
      "    V_scaler = K.ones(V_scaler_shape)  # init to ones, so effective parameters don't change\n",
      "\n",
      "    # get V parameters = ||V||/g * W\n",
      "    norm_axes = [i for i in range(len(ps) - 1)]\n",
      "    V = p / tf.reshape(V_scaler, [1] * len(norm_axes) + [-1])\n",
      "\n",
      "    # split V_scaler into ||V|| and g parameters\n",
      "    V_norm = tf.sqrt(tf.reduce_sum(tf.square(V), norm_axes))\n",
      "    g_param = V_scaler * V_norm\n",
      "\n",
      "    # get grad in V,g parameters\n",
      "    grad_g = tf.reduce_sum(g * V, norm_axes) / V_norm\n",
      "    grad_V = tf.reshape(V_scaler, [1] * len(norm_axes) + [-1]) * \\\n",
      "             (g - tf.reshape(grad_g / V_norm, [1] * len(norm_axes) + [-1]) * V)\n",
      "\n",
      "    return V, V_norm, V_scaler, g_param, grad_g, grad_V\n",
      "\n",
      "\n",
      "def add_weightnorm_param_updates(updates, new_V_param, new_g_param, W, V_scaler):\n",
      "    ps = K.get_variable_shape(new_V_param)\n",
      "    norm_axes = [i for i in range(len(ps) - 1)]\n",
      "\n",
      "    # update W and V_scaler\n",
      "    new_V_norm = tf.sqrt(tf.reduce_sum(tf.square(new_V_param), norm_axes))\n",
      "    new_V_scaler = new_g_param / new_V_norm\n",
      "    new_W = tf.reshape(new_V_scaler, [1] * len(norm_axes) + [-1]) * new_V_param\n",
      "    updates.append(K.update(W, new_W))\n",
      "    updates.append(K.update(V_scaler, new_V_scaler))\n",
      "\n",
      "\n",
      "# data based initialization for a given Keras model\n",
      "def data_based_init(model, input):\n",
      "\n",
      "    # input can be dict, numpy array, or list of numpy arrays\n",
      "    if type(input) is dict:\n",
      "        feed_dict = input\n",
      "    elif type(input) is list:\n",
      "        feed_dict = {tf_inp: np_inp for tf_inp,np_inp in zip(model.inputs,input)}\n",
      "    else:\n",
      "        feed_dict = {model.inputs[0]: input}\n",
      "\n",
      "    # add learning phase if required\n",
      "    if model.uses_learning_phase and K.learning_phase() not in feed_dict:\n",
      "        feed_dict.update({K.learning_phase(): 1})\n",
      "\n",
      "    # get all layer name, output, weight, bias tuples\n",
      "    layer_output_weight_bias = []\n",
      "    for l in model.layers:\n",
      "        if hasattr(l, 'W') and hasattr(l, 'b'):\n",
      "            assert(l.built)\n",
      "            layer_output_weight_bias.append( (l.name,l.get_output_at(0),l.W,l.b) ) # if more than one node, only use the first\n",
      "\n",
      "    # iterate over our list and do data dependent init\n",
      "    sess = K.get_session()\n",
      "    for l,o,W,b in layer_output_weight_bias:\n",
      "        print('Performing data dependent initialization for layer ' + l)\n",
      "        m,v = tf.nn.moments(o, [i for i in range(len(o.get_shape())-1)])\n",
      "        s = tf.sqrt(v + 1e-10)\n",
      "        print(s.get_shape())\n",
      "        print(W.get_shape())\n",
      "        new_W =  W/tf.reshape(s,[1]*(len(W.get_shape())-1)+[-1])\n",
      "        updates = tf.group(tf.assign(W, new_W), tf.assign(b, (b-m)/s))\n",
      "        sess.run(updates, feed_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    }
   ],
   "metadata": {}
  }
 ]
}